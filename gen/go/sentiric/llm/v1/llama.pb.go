// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.10
// 	protoc        (unknown)
// source: sentiric/llm/v1/llama.proto

package llmv1

import (
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	structpb "google.golang.org/protobuf/types/known/structpb"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

type LlamaGenerateStreamRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	SystemPrompt  string                 `protobuf:"bytes,1,opt,name=system_prompt,json=systemPrompt,proto3" json:"system_prompt,omitempty"`
	UserPrompt    string                 `protobuf:"bytes,2,opt,name=user_prompt,json=userPrompt,proto3" json:"user_prompt,omitempty"`
	RagContext    *string                `protobuf:"bytes,3,opt,name=rag_context,json=ragContext,proto3,oneof" json:"rag_context,omitempty"`
	History       []*ConversationTurn    `protobuf:"bytes,4,rep,name=history,proto3" json:"history,omitempty"`
	Params        *GenerationParams      `protobuf:"bytes,5,opt,name=params,proto3,oneof" json:"params,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *LlamaGenerateStreamRequest) Reset() {
	*x = LlamaGenerateStreamRequest{}
	mi := &file_sentiric_llm_v1_llama_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *LlamaGenerateStreamRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*LlamaGenerateStreamRequest) ProtoMessage() {}

func (x *LlamaGenerateStreamRequest) ProtoReflect() protoreflect.Message {
	mi := &file_sentiric_llm_v1_llama_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use LlamaGenerateStreamRequest.ProtoReflect.Descriptor instead.
func (*LlamaGenerateStreamRequest) Descriptor() ([]byte, []int) {
	return file_sentiric_llm_v1_llama_proto_rawDescGZIP(), []int{0}
}

func (x *LlamaGenerateStreamRequest) GetSystemPrompt() string {
	if x != nil {
		return x.SystemPrompt
	}
	return ""
}

func (x *LlamaGenerateStreamRequest) GetUserPrompt() string {
	if x != nil {
		return x.UserPrompt
	}
	return ""
}

func (x *LlamaGenerateStreamRequest) GetRagContext() string {
	if x != nil && x.RagContext != nil {
		return *x.RagContext
	}
	return ""
}

func (x *LlamaGenerateStreamRequest) GetHistory() []*ConversationTurn {
	if x != nil {
		return x.History
	}
	return nil
}

func (x *LlamaGenerateStreamRequest) GetParams() *GenerationParams {
	if x != nil {
		return x.Params
	}
	return nil
}

type LlamaGenerateStreamResponse struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Types that are valid to be assigned to Type:
	//
	//	*LlamaGenerateStreamResponse_Token
	//	*LlamaGenerateStreamResponse_FinishDetails
	Type          isLlamaGenerateStreamResponse_Type `protobuf_oneof:"type"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *LlamaGenerateStreamResponse) Reset() {
	*x = LlamaGenerateStreamResponse{}
	mi := &file_sentiric_llm_v1_llama_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *LlamaGenerateStreamResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*LlamaGenerateStreamResponse) ProtoMessage() {}

func (x *LlamaGenerateStreamResponse) ProtoReflect() protoreflect.Message {
	mi := &file_sentiric_llm_v1_llama_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use LlamaGenerateStreamResponse.ProtoReflect.Descriptor instead.
func (*LlamaGenerateStreamResponse) Descriptor() ([]byte, []int) {
	return file_sentiric_llm_v1_llama_proto_rawDescGZIP(), []int{1}
}

func (x *LlamaGenerateStreamResponse) GetType() isLlamaGenerateStreamResponse_Type {
	if x != nil {
		return x.Type
	}
	return nil
}

func (x *LlamaGenerateStreamResponse) GetToken() string {
	if x != nil {
		if x, ok := x.Type.(*LlamaGenerateStreamResponse_Token); ok {
			return x.Token
		}
	}
	return ""
}

func (x *LlamaGenerateStreamResponse) GetFinishDetails() *FinishDetails {
	if x != nil {
		if x, ok := x.Type.(*LlamaGenerateStreamResponse_FinishDetails); ok {
			return x.FinishDetails
		}
	}
	return nil
}

type isLlamaGenerateStreamResponse_Type interface {
	isLlamaGenerateStreamResponse_Type()
}

type LlamaGenerateStreamResponse_Token struct {
	Token string `protobuf:"bytes,1,opt,name=token,proto3,oneof"` // UTF-8 string olarak token
}

type LlamaGenerateStreamResponse_FinishDetails struct {
	FinishDetails *FinishDetails `protobuf:"bytes,2,opt,name=finish_details,json=finishDetails,proto3,oneof"`
}

func (*LlamaGenerateStreamResponse_Token) isLlamaGenerateStreamResponse_Type() {}

func (*LlamaGenerateStreamResponse_FinishDetails) isLlamaGenerateStreamResponse_Type() {}

type ConversationTurn struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Role          string                 `protobuf:"bytes,1,opt,name=role,proto3" json:"role,omitempty"` // "user", "assistant", "system"
	Content       string                 `protobuf:"bytes,2,opt,name=content,proto3" json:"content,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ConversationTurn) Reset() {
	*x = ConversationTurn{}
	mi := &file_sentiric_llm_v1_llama_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ConversationTurn) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ConversationTurn) ProtoMessage() {}

func (x *ConversationTurn) ProtoReflect() protoreflect.Message {
	mi := &file_sentiric_llm_v1_llama_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ConversationTurn.ProtoReflect.Descriptor instead.
func (*ConversationTurn) Descriptor() ([]byte, []int) {
	return file_sentiric_llm_v1_llama_proto_rawDescGZIP(), []int{2}
}

func (x *ConversationTurn) GetRole() string {
	if x != nil {
		return x.Role
	}
	return ""
}

func (x *ConversationTurn) GetContent() string {
	if x != nil {
		return x.Content
	}
	return ""
}

type GenerationParams struct {
	state             protoimpl.MessageState `protogen:"open.v1"`
	MaxNewTokens      *int32                 `protobuf:"varint,1,opt,name=max_new_tokens,json=maxNewTokens,proto3,oneof" json:"max_new_tokens,omitempty"`
	Temperature       *float32               `protobuf:"fixed32,2,opt,name=temperature,proto3,oneof" json:"temperature,omitempty"`
	TopK              *int32                 `protobuf:"varint,3,opt,name=top_k,json=topK,proto3,oneof" json:"top_k,omitempty"`
	TopP              *float32               `protobuf:"fixed32,4,opt,name=top_p,json=topP,proto3,oneof" json:"top_p,omitempty"`
	RepetitionPenalty *float32               `protobuf:"fixed32,5,opt,name=repetition_penalty,json=repetitionPenalty,proto3,oneof" json:"repetition_penalty,omitempty"`
	StopSequences     []string               `protobuf:"bytes,6,rep,name=stop_sequences,json=stopSequences,proto3" json:"stop_sequences,omitempty"`
	Seed              *int64                 `protobuf:"varint,7,opt,name=seed,proto3,oneof" json:"seed,omitempty"`
	// Motor spesifik ekstra parametreler (Ã¶rn: mirostat)
	EngineSpecificParams *structpb.Struct `protobuf:"bytes,20,opt,name=engine_specific_params,json=engineSpecificParams,proto3,oneof" json:"engine_specific_params,omitempty"`
	unknownFields        protoimpl.UnknownFields
	sizeCache            protoimpl.SizeCache
}

func (x *GenerationParams) Reset() {
	*x = GenerationParams{}
	mi := &file_sentiric_llm_v1_llama_proto_msgTypes[3]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GenerationParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GenerationParams) ProtoMessage() {}

func (x *GenerationParams) ProtoReflect() protoreflect.Message {
	mi := &file_sentiric_llm_v1_llama_proto_msgTypes[3]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GenerationParams.ProtoReflect.Descriptor instead.
func (*GenerationParams) Descriptor() ([]byte, []int) {
	return file_sentiric_llm_v1_llama_proto_rawDescGZIP(), []int{3}
}

func (x *GenerationParams) GetMaxNewTokens() int32 {
	if x != nil && x.MaxNewTokens != nil {
		return *x.MaxNewTokens
	}
	return 0
}

func (x *GenerationParams) GetTemperature() float32 {
	if x != nil && x.Temperature != nil {
		return *x.Temperature
	}
	return 0
}

func (x *GenerationParams) GetTopK() int32 {
	if x != nil && x.TopK != nil {
		return *x.TopK
	}
	return 0
}

func (x *GenerationParams) GetTopP() float32 {
	if x != nil && x.TopP != nil {
		return *x.TopP
	}
	return 0
}

func (x *GenerationParams) GetRepetitionPenalty() float32 {
	if x != nil && x.RepetitionPenalty != nil {
		return *x.RepetitionPenalty
	}
	return 0
}

func (x *GenerationParams) GetStopSequences() []string {
	if x != nil {
		return x.StopSequences
	}
	return nil
}

func (x *GenerationParams) GetSeed() int64 {
	if x != nil && x.Seed != nil {
		return *x.Seed
	}
	return 0
}

func (x *GenerationParams) GetEngineSpecificParams() *structpb.Struct {
	if x != nil {
		return x.EngineSpecificParams
	}
	return nil
}

type FinishDetails struct {
	state            protoimpl.MessageState `protogen:"open.v1"`
	FinishReason     string                 `protobuf:"bytes,1,opt,name=finish_reason,json=finishReason,proto3" json:"finish_reason,omitempty"` // "stop", "length", "error"
	PromptTokens     int32                  `protobuf:"varint,2,opt,name=prompt_tokens,json=promptTokens,proto3" json:"prompt_tokens,omitempty"`
	CompletionTokens int32                  `protobuf:"varint,3,opt,name=completion_tokens,json=completionTokens,proto3" json:"completion_tokens,omitempty"`
	unknownFields    protoimpl.UnknownFields
	sizeCache        protoimpl.SizeCache
}

func (x *FinishDetails) Reset() {
	*x = FinishDetails{}
	mi := &file_sentiric_llm_v1_llama_proto_msgTypes[4]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *FinishDetails) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*FinishDetails) ProtoMessage() {}

func (x *FinishDetails) ProtoReflect() protoreflect.Message {
	mi := &file_sentiric_llm_v1_llama_proto_msgTypes[4]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use FinishDetails.ProtoReflect.Descriptor instead.
func (*FinishDetails) Descriptor() ([]byte, []int) {
	return file_sentiric_llm_v1_llama_proto_rawDescGZIP(), []int{4}
}

func (x *FinishDetails) GetFinishReason() string {
	if x != nil {
		return x.FinishReason
	}
	return ""
}

func (x *FinishDetails) GetPromptTokens() int32 {
	if x != nil {
		return x.PromptTokens
	}
	return 0
}

func (x *FinishDetails) GetCompletionTokens() int32 {
	if x != nil {
		return x.CompletionTokens
	}
	return 0
}

var File_sentiric_llm_v1_llama_proto protoreflect.FileDescriptor

const file_sentiric_llm_v1_llama_proto_rawDesc = "" +
	"\n" +
	"\x1bsentiric/llm/v1/llama.proto\x12\x0fsentiric.llm.v1\x1a\x1cgoogle/protobuf/struct.proto\"\xa0\x02\n" +
	"\x1aLlamaGenerateStreamRequest\x12#\n" +
	"\rsystem_prompt\x18\x01 \x01(\tR\fsystemPrompt\x12\x1f\n" +
	"\vuser_prompt\x18\x02 \x01(\tR\n" +
	"userPrompt\x12$\n" +
	"\vrag_context\x18\x03 \x01(\tH\x00R\n" +
	"ragContext\x88\x01\x01\x12;\n" +
	"\ahistory\x18\x04 \x03(\v2!.sentiric.llm.v1.ConversationTurnR\ahistory\x12>\n" +
	"\x06params\x18\x05 \x01(\v2!.sentiric.llm.v1.GenerationParamsH\x01R\x06params\x88\x01\x01B\x0e\n" +
	"\f_rag_contextB\t\n" +
	"\a_params\"\x86\x01\n" +
	"\x1bLlamaGenerateStreamResponse\x12\x16\n" +
	"\x05token\x18\x01 \x01(\tH\x00R\x05token\x12G\n" +
	"\x0efinish_details\x18\x02 \x01(\v2\x1e.sentiric.llm.v1.FinishDetailsH\x00R\rfinishDetailsB\x06\n" +
	"\x04type\"@\n" +
	"\x10ConversationTurn\x12\x12\n" +
	"\x04role\x18\x01 \x01(\tR\x04role\x12\x18\n" +
	"\acontent\x18\x02 \x01(\tR\acontent\"\xd2\x03\n" +
	"\x10GenerationParams\x12)\n" +
	"\x0emax_new_tokens\x18\x01 \x01(\x05H\x00R\fmaxNewTokens\x88\x01\x01\x12%\n" +
	"\vtemperature\x18\x02 \x01(\x02H\x01R\vtemperature\x88\x01\x01\x12\x18\n" +
	"\x05top_k\x18\x03 \x01(\x05H\x02R\x04topK\x88\x01\x01\x12\x18\n" +
	"\x05top_p\x18\x04 \x01(\x02H\x03R\x04topP\x88\x01\x01\x122\n" +
	"\x12repetition_penalty\x18\x05 \x01(\x02H\x04R\x11repetitionPenalty\x88\x01\x01\x12%\n" +
	"\x0estop_sequences\x18\x06 \x03(\tR\rstopSequences\x12\x17\n" +
	"\x04seed\x18\a \x01(\x03H\x05R\x04seed\x88\x01\x01\x12R\n" +
	"\x16engine_specific_params\x18\x14 \x01(\v2\x17.google.protobuf.StructH\x06R\x14engineSpecificParams\x88\x01\x01B\x11\n" +
	"\x0f_max_new_tokensB\x0e\n" +
	"\f_temperatureB\b\n" +
	"\x06_top_kB\b\n" +
	"\x06_top_pB\x15\n" +
	"\x13_repetition_penaltyB\a\n" +
	"\x05_seedB\x19\n" +
	"\x17_engine_specific_params\"\x86\x01\n" +
	"\rFinishDetails\x12#\n" +
	"\rfinish_reason\x18\x01 \x01(\tR\ffinishReason\x12#\n" +
	"\rprompt_tokens\x18\x02 \x01(\x05R\fpromptTokens\x12+\n" +
	"\x11completion_tokens\x18\x03 \x01(\x05R\x10completionTokens2}\n" +
	"\fLlamaService\x12m\n" +
	"\x0eGenerateStream\x12+.sentiric.llm.v1.LlamaGenerateStreamRequest\x1a,.sentiric.llm.v1.LlamaGenerateStreamResponse0\x01BEZCgithub.com/sentiric/sentiric-contracts/gen/go/sentiric/llm/v1;llmv1b\x06proto3"

var (
	file_sentiric_llm_v1_llama_proto_rawDescOnce sync.Once
	file_sentiric_llm_v1_llama_proto_rawDescData []byte
)

func file_sentiric_llm_v1_llama_proto_rawDescGZIP() []byte {
	file_sentiric_llm_v1_llama_proto_rawDescOnce.Do(func() {
		file_sentiric_llm_v1_llama_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_sentiric_llm_v1_llama_proto_rawDesc), len(file_sentiric_llm_v1_llama_proto_rawDesc)))
	})
	return file_sentiric_llm_v1_llama_proto_rawDescData
}

var file_sentiric_llm_v1_llama_proto_msgTypes = make([]protoimpl.MessageInfo, 5)
var file_sentiric_llm_v1_llama_proto_goTypes = []any{
	(*LlamaGenerateStreamRequest)(nil),  // 0: sentiric.llm.v1.LlamaGenerateStreamRequest
	(*LlamaGenerateStreamResponse)(nil), // 1: sentiric.llm.v1.LlamaGenerateStreamResponse
	(*ConversationTurn)(nil),            // 2: sentiric.llm.v1.ConversationTurn
	(*GenerationParams)(nil),            // 3: sentiric.llm.v1.GenerationParams
	(*FinishDetails)(nil),               // 4: sentiric.llm.v1.FinishDetails
	(*structpb.Struct)(nil),             // 5: google.protobuf.Struct
}
var file_sentiric_llm_v1_llama_proto_depIdxs = []int32{
	2, // 0: sentiric.llm.v1.LlamaGenerateStreamRequest.history:type_name -> sentiric.llm.v1.ConversationTurn
	3, // 1: sentiric.llm.v1.LlamaGenerateStreamRequest.params:type_name -> sentiric.llm.v1.GenerationParams
	4, // 2: sentiric.llm.v1.LlamaGenerateStreamResponse.finish_details:type_name -> sentiric.llm.v1.FinishDetails
	5, // 3: sentiric.llm.v1.GenerationParams.engine_specific_params:type_name -> google.protobuf.Struct
	0, // 4: sentiric.llm.v1.LlamaService.GenerateStream:input_type -> sentiric.llm.v1.LlamaGenerateStreamRequest
	1, // 5: sentiric.llm.v1.LlamaService.GenerateStream:output_type -> sentiric.llm.v1.LlamaGenerateStreamResponse
	5, // [5:6] is the sub-list for method output_type
	4, // [4:5] is the sub-list for method input_type
	4, // [4:4] is the sub-list for extension type_name
	4, // [4:4] is the sub-list for extension extendee
	0, // [0:4] is the sub-list for field type_name
}

func init() { file_sentiric_llm_v1_llama_proto_init() }
func file_sentiric_llm_v1_llama_proto_init() {
	if File_sentiric_llm_v1_llama_proto != nil {
		return
	}
	file_sentiric_llm_v1_llama_proto_msgTypes[0].OneofWrappers = []any{}
	file_sentiric_llm_v1_llama_proto_msgTypes[1].OneofWrappers = []any{
		(*LlamaGenerateStreamResponse_Token)(nil),
		(*LlamaGenerateStreamResponse_FinishDetails)(nil),
	}
	file_sentiric_llm_v1_llama_proto_msgTypes[3].OneofWrappers = []any{}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_sentiric_llm_v1_llama_proto_rawDesc), len(file_sentiric_llm_v1_llama_proto_rawDesc)),
			NumEnums:      0,
			NumMessages:   5,
			NumExtensions: 0,
			NumServices:   1,
		},
		GoTypes:           file_sentiric_llm_v1_llama_proto_goTypes,
		DependencyIndexes: file_sentiric_llm_v1_llama_proto_depIdxs,
		MessageInfos:      file_sentiric_llm_v1_llama_proto_msgTypes,
	}.Build()
	File_sentiric_llm_v1_llama_proto = out.File
	file_sentiric_llm_v1_llama_proto_goTypes = nil
	file_sentiric_llm_v1_llama_proto_depIdxs = nil
}
